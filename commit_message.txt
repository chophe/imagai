feat: Add OpenRouter chat.completions support for Gemini models

This commit introduces comprehensive support for OpenRouter's chat.completions API, specifically tailored for Gemini-like models, enabling vision capabilities and text-based responses within Imagai.

Key changes include:

- **`openai_sdk_provider.py`**: Implemented conditional logic to route requests to `chat.completions` when the base URL is OpenRouter and the model is Gemini-like. This includes constructing multi-part messages (text and optional image URLs) and incorporating OpenRouter-specific `HTTP-Referer` and `X-Title` headers from environment variables. Textual responses are now extracted into the `text_content` field of `ImageGenerationResponse`.

- **`core.py`**: Modified `generate_image_core` to gracefully handle responses that contain only `text_content` (e.g., from OpenRouter's chat completions). If no image URL or base64 data is present, the image saving logic is bypassed, and the text content is returned without being flagged as an error.

- **`cli.py`**: Enhanced the command-line interface to support the new functionality:
  - Added a `--image-url` option to allow users to provide an image URL for vision models (e.g., for Gemini via OpenRouter).
  - Updated the output display to show a dedicated "Model Response" panel for `text_content` when no image payload is returned.
  - Ensured continued sanitization of `stdin` prompts to remove ASCII control characters (like `\x1A` from Windows Ctrl+Z).

These changes allow Imagai to interact with OpenRouter's chat-based vision models, providing a more versatile image generation and analysis tool. Users can now configure OpenRouter engines with Gemini models and receive textual interpretations or responses, alongside existing image generation capabilities.